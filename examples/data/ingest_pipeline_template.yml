####################################################################
# MHKiT-CLOUD INGEST PIPELINE CONFIGURATION TEMPLATE
#
# This file contains an annotated example of how to configure an
# MHKiT-Cloud data processing pipeline.
####################################################################

####################################################################
# PART 1: DATASET DEFINITION
# Define dimensions, variables, and metadata that will be included
# in your processed, standardized data file.
####################################################################
dataset_definition:
  #-----------------------------------------------------------------
  # Global Attributes (general metadata)
  #
  # All optional attributes are commented out.  You may remove them
  # if not applicable to your data.
  #
  # You may add any additional attributes as needed to describe your
  # data collection and processing activities.
  #-----------------------------------------------------------------
  attributes:

    # A succinct English language description of what is in the dataset.
    # The value would be similar to a publication title.
    # Example: "Atmospheric Radiation Measurement (ARM) program Best
    # Estimate cloud and radiation measurements (ARMBECLDRAD)"
    title: Buoy Dataset for Buoy \#120

    # Longer English language description of the data.
    # Example: "ARM best estimate hourly averaged QC controlled product,
    # derived from ARM observational Value-Added Product data: ARSCL,
    # MWRRET, QCRAD, TSI, and satellite; see input_files for the names of
    # original files used in calculation of this product"
    description: Example ingest dataset used for demonstration purposes.

    # The version of the standards document this data conforms to.
    conventions: MHKiT-Cloud Data Standards v. 1.0

    # If an optional Digital Object Identifier (DOI) has been obtained
    # for the data, it may be included here.
    #doi: 10.21947/1671051

    # The institution who produced the data
    #institution: PNNL

    # Include the url to the specific tagged release of the code
    # used for this pipeline invocation.
    # Example,  https://github.com/clansing/twrmr/releases/tag/1.0.
    # Note that MHKiT-Cloud will automatically create a new code
    # release whenever the pipeline is deployed to production and
    # record this attribute automatically.
    code_url: https://github.com/clansing/tsdat/releases/tag/1.0

    # Published or web-based references that describe the methods
    # algorithms, or third party libraries used to process the data.
    # Example: https://github.com/MHKiT-Software/MHKiT-Python
    #references:

    #---------------------------------------------------------------
    # The following attributes used to create the datastream name
    # datastream_name = (location_id).(instrument_id)(qualifier)(temporal).data_level
    #---------------------------------------------------------------

    # A label for the location where the data were obtained from
    location_id: humboldt_z05

    # A string consisting of any letters, digits, "-" or "_" that can
    # be used to uniquely identify the instrument used to produce
    # the data.  To prevent confusion with the temporal resolution
    # of the instrument, the instrument identifier must not end
    # with a number.
    instrument_id: lidar_buoy

    # An optional qualifier that distinguishes these data from other
    # data sets produced by the same instrument.  The qualifier
    # must not end with a number.
    #qualifier:

    # A optional description of the data temporal resolution
    # (e.g., 30m, 1h, 200ms, 14d).  All temporal resolution
    # descriptors require a units identifier.  Accepted
    # abbreviations include: ns=nanosecond, us=microsecond,
    # ms=millisecond, s=second, m=minute, h=hour, d=day, mo=month,
    # yr=year.
    #temporal: 10m

    # The processing level of the data (e.g., 00, b1, c1, etc.)
    # as described in the MHKiT-Cloud Data Standards.
    # A two-character descriptor consisting of one lower-case
    # letter followed by one number
    data_level: b1

    #---------------------------------------------------------------

    # A more detailed description of the site location.
    #location_meaning: Buoy is located of the coast of Humboldt, CA

    # Name of instrument(s) used to collect data.
    #instrument_name: Wind Sentinel

    # Serial number of instrument(s) used to collect data.
    #serial_number: '000011312'

    # Description of instrument(s) used to collect data.
    #instrument_meaning: Self-powered floating buoy hosting a suite of meteorological and marine instruments.

    # Manufacturer of instrument(s) used to collect data.
    #instrument_manufacturer: AXYS Technologies Inc.

    # The date(s) of the last time the instrument(s) was calibrated.
    #last_calibration_date

    # The expected sampling interval of the instrument (e.g., "400 us")
    #sampling_interval: 10 min

  #-----------------------------------------------------------------
  # Dimensions (shape)
  #-----------------------------------------------------------------
  dimensions:
    # All time series data must have a "time" dimension
    # TODO: provide a link to the documentation online
    time:
        length: unlimited

  #-----------------------------------------------------------------
  # Variables
  #-----------------------------------------------------------------
  variables:

    #---------------------------------------------------------------
    # All time series data must have a "time" coordinate variable which
    # contains the data values for the time dimension
    # TODO: provide a link to the documentation online
    #---------------------------------------------------------------
    time:  # Variable name as it will appear in the processed data

      #---------------------------------------------------------------
      # The input section for each variable is used to specify the
      # mapping between the raw data file and the processed output data
      #---------------------------------------------------------------
      input:
        # Name of the variable in the raw data
        name: DataTimeStamp(DateTime)

        #-------------------------------------------------------------
        # A converter is used to convert the raw data into standardized
        # values.
        #-------------------------------------------------------------
        # Use the StringTimeConverter if your raw data provides time
        # as a formatted string.
        converter:
          classname: tsdat.utils.converters.StringTimeConverter
          parameters:
            # A list of timezones can be found here:
            # https://en.wikipedia.org/wiki/List_of_tz_database_time_zones
            timezone: US/Pacific
            time_format: "%Y-%m-%d %H:%M:%S"

        # Use the TimestampTimeConverter if your raw data provides time
        # as a numeric UTC timestamp
        #converter:
        #  classname: tsdat.utils.converters.TimestampTimeConverter
        #  parameters:
        #    # Unit of the numeric value as used by pandas.to_datetime (D,s,ms,us,ns)
        #    unit: s

      # The shape of this variable.  All coordinate variables (e.g., time) must
      # have a single dimension that exactly matches the variable name
      dims: [time]

      # The data type of the variable.  Can be one of:
      # [byte, ubyte, char, short, ushort, int32 (or int), uint32 (or uint),
      # int64 (or long), uint64 (or ulong), float, double, string]
      type: long

      #-------------------------------------------------------------
      # The attrs section define the attributes (metadata) that will
      # be set for this variable.
      #
      # All optional attributes are commented out.  You may remove them
      # if not applicable to your data.
      #
      # You may add any additional attributes as needed to describe your
      # variables.
      #
      # Any metadata used for QC tests will be indicated.
      #-------------------------------------------------------------
      attrs:

        # A minimal description of what the variable represents.
        long_name: Time offset from epoch

        # A string exactly matching a value in from the CF or MRE
        # Standard Name table, if a match exists
        #standard_name: time

        # A CFUnits-compatible string indicating the units the data
        # are measured in.
        # https://cfconventions.org/Data/cf-conventions/cf-conventions-1.8/cf-conventions.html#units
        #
        # Note:  CF Standards require this exact format for time.
        # UTC is strongly recommended.
        # https://cfconventions.org/Data/cf-conventions/cf-conventions-1.8/cf-conventions.html#time-coordinate
        units: seconds since 1970-01-01T00:00:00

    #-----------------------------------------------------------------
    # Mean temperature variable (non-coordinate variable)
    #-----------------------------------------------------------------
    temp_mean: # Variable name as it will appear in the processed data

      #---------------------------------------------------------------
      # The input section for each variable is used to specify the
      # mapping between the raw data file and the processed output data
      #---------------------------------------------------------------
      input:
        # Name of the variable in the raw data
        name: ValueAverage(Double)

        # Units of the variable in the raw data
        units: degC

        #-------------------------------------------------------------
        # A converter is used to convert the raw data into standardized
        # values.
        #
        # Use the DefaultConverter for all non-time variables that
        # use units supported by udunits2.
        # https://www.unidata.ucar.edu/software/udunits/udunits-2.2.28/udunits2.html#Database
        #
        # If your raw data has units that are not supported by udunits2,
        # you can specify your own Converter class.
        #-------------------------------------------------------------
        converter:
          classname: tsdat.utils.converters.DefaultConverter

      # The shape of this variable
      dims: [time]

      # The data type of the variable.  Can be one of:
      # [byte, ubyte, char, short, ushort, int32 (or int), uint32 (or uint),
      # int64 (or long), uint64 (or ulong), float, double, string]
      type: double

      #-------------------------------------------------------------
      # The attrs section define the attributes (metadata) that will
      # be set for this variable.
      #
      # All optional attributes are commented out.  You may remove them
      # if not applicable to your data.
      #
      # You may add any additional attributes as needed to describe your
      # variables.
      #
      # Any metadata used for QC tests will be indicated.
      #-------------------------------------------------------------
      attrs:
        # A minimal description of what the variable represents.
        long_name: Mean temperature

        # An optional attribute to provide human-readable context for what this variable
        # represents, how it was measured, or anything else that would be relevant to end-users.
        #comment: Rolling 10-minute average sea surface temperature. Aligned such that the temperature reported at time 'n' represents the average across the interval (n-1, n].

        # A CFUnits-compatible string indicating the units the data
        # are measured in.
        # https://cfconventions.org/Data/cf-conventions/cf-conventions-1.8/cf-conventions.html#units
        units: degC

        # The value used to initialize the variableâ€™s data. Defaults to -9999.
        # Coordinate variables must not use this attribute.
        #_FillValue: -9999

        # An array of variable names that depend on the values from this variable. This is primarily
        # used to indicate if a variable has an ancillary qc variable.
        # NOTE: QC ancillary variables will be automatically recorded via the MHKiT-Cloud pipeline engine.
        #ancillary_variables: []

        # A two-element array of [min, max] representing the smallest and largest valid values
        # of a variable.  Values outside valid_range will be filled with _FillValue.
        #valid_range: [-50, 50]

        # The maximum allowed difference between any two consecutive values of a variable,
        # values outside of which should be flagged as "Bad".
        # This attribute is used for the valid_delta QC test.  If not specified, this
        # variable will be omitted from the test.
        #valid_delta: 0.25

        # A two-element array of [min, max] outside of which the data should be flagged as "Bad".
        # This attribute is used for the fail_min and fail_max QC tests.
        # If not specified, this variable will be omitted from these tests.
        #fail_range: [0, 40]

        # A two-element array of [min, max] outside of which the data should be flagged as "Indeterminate".
        # This attribute is used for the warn_min and warn_max QC tests.
        # If not specified, this variable will be omitted from these tests.
        #warn_range: [0, 30]

        # An array of strings indicating what corrections, if any, have been applied to the data.
        #corrections_applied: []

        # The height of the instrument above ground level (AGL), or in the case of above
        # water, above the surface.
        #sensor_height: 30m

    #-----------------------------------------------------------------
    # Example of a variables that hold a single scalar value that
    # is not present in the raw data.
    #-----------------------------------------------------------------
    latitude:
      type: float

      #<-----This variable has no input, which means it will be set by
      # the pipeline and not pulled from the raw data

      #<-----This variable has no dimensions, which means it will be
      # a scalar value

      attrs:
        long_name: North latitude
        standard_name: latitude
        comment: Recorded lattitude at the instrument location
        units: degree_N
        valid_range:[-90.f, 90.f]

      data: 71.323 #<-----The data field can be used to specify a pre-set value

      longitude:
        type: float
        attrs:
          long_name: East longitude
          standard_name: longitude
          comment: Recorded longitude at the instrument location
          units: degree_E
          valid_range:[-180.f, 180.f]
        data: -156.609

    #-----------------------------------------------------------------
    # Example of a variable that is derived by the processing pipeline
    #-----------------------------------------------------------------
    foo:
      type: float

      #<-----This variable has no input, which means it will be set by
      # the pipeline and not pulled from the raw data

      dims: [time]

      attrs:
        long_name: some other property
        units: kg/m^3
        comment: Computed from temp_mean point value using some formula...
        references: [http://sccoos.org/data/autoss/, http://sccoos.org/about/dmac/]

---
####################################################################
# PART 2: QC TESTS
# Define the QC tests that will be applied to variable data.
####################################################################
coordinate_variable_qc_tests:
  #-----------------------------------------------------------------
  # The following section defines the default qc tests that will be
  # performed on coordinate variables in a dataset.  Note that by
  # default, coordinate variable tests will NOT set a QC bit and
  # will trigger a critical pipeline failure.  This is because
  # Problems with coordinate variables are considered to cause
  # the dataset to be unusable and should be manually reviewed.
  #
  # However, the user may override the default coordinate variable
  # tests and error handlers if they feel that data correction is
  # warranted.
  #
  # For a complete list of tests provided by MHKiT-Cloud, please see
  # the tsdat.qc.operators package.
  #
  # Users are also free to add custom tests defined by their own
  # operator classes.
  #-----------------------------------------------------------------
  missing:
    variables:
      - ALL  # keyword to apply test to all coordinate variables
    operator:
      classname: tsdat.qc.operators.CheckMissing
    error_handlers:
      fail_pipeline:
        classname: tsdat.qc.error_handlers.FailPipeline

  monotonic:
    variables:
      - All  # keyword to apply test to all coordinate variables
    operator:
      classname: tsdat.qc.operators.CheckMonotonic
    error_handlers:
      fail_pipeline:
        classname: tsdat.qc.error_handlers.FailPipeline

qc_tests:
  #-----------------------------------------------------------------
  # The following section defines the default qc tests that will be
  # performed on non-coordinate variables in a dataset.  All
  # non-coordinate variables that have the appropriate metadata
  # attributes will be included in the test.
  #
  # For a complete list of tests provided by MHKiT-Cloud, please see
  # the tsdat.qc.operators package.
  #
  # Users are also free to add custom tests defined by their own
  # operator classes.
  #-----------------------------------------------------------------

  missing:  # the name of the test

    # The bit (1-32) used to record the results of this test (0/1).
    # A 0 value means the test passed.  A 1 value means the
    # test failed.
    qc_bit: 1

    # The description of the QC test performed
    meaning: "Value is equal to _FillValue or NaN"

    # The assessment of the test.  Must be one of [Bad, Indeterminate]
    assessment: Bad

    # Which variables to apply the test to
    variables:
      - ALL  # keyword to apply test to all non-coordinate variables

    # The class that will implement the test.  Users are free
    # to override with their own class if they want to change
    # behavior.
    operator:
      classname: tsdat.qc.operators.CheckMissing

    error_handlers:
      # Replace any NaNs with _FillValue
      replace_with_fill_value:
        classname: tsdat.qc.error_handlers.RemoveFailedValues

  fail_min:
    qc_bit: 2
    meaning: "Value is less than the fail_range."
    assessment: Bad
    variables:
      - ALL
    operator:
      classname: tsdat.qc.operators.CheckFailMin

  fail_max:
    qc_bit: 3
    meaning: "Value is greater than the fail_range."
    assessment: Bad
    variables:
      - ALL
    operator:
      classname: tsdat.qc.operators.CheckFailMax

  warn_min:
    qc_bit: 4
    meaning: "Value is less than the warn_range."
    assessment: Indeterminate
    variables:
      - ALL
    operator:
      classname: tsdat.qc.operators.CheckWarnMin

  warn_max:
    qc_bit: 5
    meaning: "Value is greater than the warn_range."
    assessment: Indeterminate
    variables:
      - ALL
    operator:
      classname: tsdat.qc.operators.CheckWarnMax

  valid_delta:
    qc_bit: 6
    meaning: "Difference between current and previous values exceeds valid_delta."
    assessment: Indeterminate
    variables:
      - ALL
    operator:
      classname: tsdat.qc.operators.CheckValidDelta
      parameters: #<====Parameters can be passed to any operator
        dim: time # specify the dimension over which to compute the delta

    #-----------------------------------------------------------------
    # Example of a user-created test that shows how to specify
    # an error handler.  Error handlers may be optionally added to
    # any of the tests described above.
    #-----------------------------------------------------------------
    temp_test:
        qc_bit: 7
        meaning: "Test for some special condition in temperature."
        assessment: Indeterminate
        variables:
          - temp_mean
        operator:
          classname: myproject.qc.operators.TestTemp

        #-------------------------------------------------------------
        # See the tsdat.qc.error_handlers package for a list of
        # available error handlers.
        #-------------------------------------------------------------
        error_handlers:

          # This error handler will notify users via email.  The
          # datastream name, variable, and failing values will be
          # included.
          send_email:
            classname: tsdat.qc.error_handlers.SendEmailAWS
            parameters:
              message: "Test failed..."
              recipients: [carina.lansing@pnnl.gov, maxwell.levin@pnnl.gov]

